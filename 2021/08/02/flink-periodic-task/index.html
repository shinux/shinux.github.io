<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><title>Flink periodic task</title><link rel="stylesheet" href="/css/normalize.css"><link rel="stylesheet" href="/css/heti.min.css"><link rel="stylesheet" href="/css/hexo-theme-adoubi.css"><link rel="icon" href="/images/favicon.ico"></head><body><div class="header"><a class="github-link" href="https://github.com/shinux"><img class="github-image" src="/images/Aquicon-Github-small.png"></a><a class="email-link" href="mailto:askb@me.com"><img class="email-image" src="/images/email-small.png"></a><a class="subscribe-link" href="/atom.xml"><img class="subscribe-image" src="/images/subscribe-small.png"></a></div><div class="content"><div class="post-item"></div><h2 class="post-title-wrapper"><p class="post-title">Flink periodic task</p></h2><div class="post-date"><time datetime="2021-08-02T07:46:16.000Z">2021-08-02</time></div><div class="post-content"><h3 id="从传统-main-入口函数到-Flink-执行环境"><a href="#从传统-main-入口函数到-Flink-执行环境" class="headerlink" title="从传统 main 入口函数到 Flink 执行环境"></a>从传统 main 入口函数到 Flink 执行环境</h3><p>在传统的 Java 程序中，main 函数是整个 Project 的唯一执行起点，在 spring（boot) 等框架下，更是可以把很多全局生效的注解写到 main 方法所在的类上，很多 scheduler executor 也可以放到 main 中。</p>
<p>然而，因为分布式 Flink 集群与本地的 standalone flink 环境有很大差距。以及Flink 程序本质是并行和分布式的，执行过程中，一个数据流会像 kafka 一样分区，流数据的处理也会包含多个子任务，子任务之间是相互独立的，并且可能在不同的线程甚至不同的机器、容器中执行。所以实际上我们在 main 里的方法定义，和环境中从 source iterator 中读取的每一份数据所在的执行环境，完全是两个不同的 Runtime (?)。</p>
<h3 id="在-Flink-中写定时任务"><a href="#在-Flink-中写定时任务" class="headerlink" title="在 Flink 中写定时任务"></a>在 Flink 中写定时任务</h3><p>初衷是将数据流中，有共性并且可以延迟处理的内容通过缓存承载，然后在定时任务中聚合后再做执行。</p>
<h4 id="第一版-Guava-scheduled-thread-pool"><a href="#第一版-Guava-scheduled-thread-pool" class="headerlink" title="第一版 Guava + scheduled thread pool"></a>第一版 Guava + scheduled thread pool</h4><p>傻乎乎的以为 flink 任务只是分发的形式，所以采用了 Google 的 Guava 内存缓存，在 source 的每一份 stream 中，然后通过定义在 main 方法中的 <code>executor.scheduleAtFixedRate</code> 做定时任务，妄图拿到所有算子中存下的缓存：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ScheduledThreadPoolExecutor executor = (ScheduledThreadPoolExecutor) Executors.newScheduledThreadPool(<span class="number">10</span>);</span><br><span class="line">executor.scheduleAtFixedRate(<span class="keyword">new</span> LazyOperationScheduler(), <span class="number">30</span>, <span class="number">30</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure>

<p>在 IDE 中 work，在本地的 standalone 模式节点中也 work，但是通过 yarn 提交到 hadoop 中的集群版本 flink 后，果然这部分代码根本没有执行。</p>
<p>我开始明白，stream handler 中的 memory 和 main 中的 memory 根本是两份不同的东西（确实不是同一份，但是这里还是想错了）。</p>
<h4 id="第二版-Redis"><a href="#第二版-Redis" class="headerlink" title="第二版 Redis"></a>第二版 Redis</h4><p>既然不能共享执行环境的内存（缓存），那就用外部的缓存吧。</p>
<p>最终表现和第一版基本一致，在 hanlder 中写 Redis 当然没有问题，但是 web server 形式的定时任务，根本无法在 Flink 中正确执行，甚至连 log 都不会打出。</p>
<h4 id="第三版-fake-continuous-source-time-window"><a href="#第三版-fake-continuous-source-time-window" class="headerlink" title="第三版 fake continuous source + time window"></a>第三版 fake continuous source + time window</h4><p>终于意识到，Flink 算子的执行，严格依赖数据流，没有流的存在，任何东西都不会持续执行。</p>
<p>于是设计了一个假的生成数据流推进，然后通过 time window 做定时的聚合，在聚合结果中，做想做的定时任务。</p>
<p>虚假的数据流生成方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.Thread.sleep;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RandomLongSource</span> <span class="keyword">extends</span> <span class="title">RichParallelSourceFunction</span>&lt;<span class="title">Long</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> cancelled = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">private</span> Random random;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">        random = <span class="keyword">new</span> Random();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Long&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (!cancelled) &#123;</span><br><span class="line">            Long nextLong = random.nextLong();</span><br><span class="line">            <span class="keyword">synchronized</span> (ctx.getCheckpointLock()) &#123;</span><br><span class="line">                ctx.collect(nextLong);</span><br><span class="line">            &#125;</span><br><span class="line">            sleep(<span class="number">30000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        cancelled = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>数据流存储（这里什么也不做，只是把数据缓存下来，只为这份 DataStream 在后续做时间窗口操作）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;Long&gt; randomLongs = env.addSource(<span class="keyword">new</span> RandomLongSource())</span><br><span class="line">                .map((MapFunction&lt;Long, Long&gt;) s -&gt; s);</span><br></pre></td></tr></table></figure>

<p>然后就是最终实现定时任务的地方，对上面存储的数据流做时间窗口操作，这里是每30秒一次：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">randomLongs.timeWindowAll(Time.seconds(<span class="number">30</span>))</span><br><span class="line">                .apply(<span class="keyword">new</span> AllWindowFunction&lt;Long, Object, TimeWindow&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(TimeWindow timeWindow, Iterable&lt;Long&gt; iterable, Collector&lt;Object&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">                        logger.info(<span class="string">"Start periodic tasks..."</span>);</span><br><span class="line">                        <span class="keyword">new</span> LazyOperationScheduler().run();</span><br><span class="line">                        logger.info(<span class="string">"periodic task finished! take time: "</span> + (System.currentTimeMillis() - start));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br></pre></td></tr></table></figure>

<p>apply 是一个必须重写的方法，在这里我们可以拿到 iterator 形式的 DataStream，里面是符合窗口条件的数据。但是这里我们其实完全没有去碰这些无用的数据 ，我们只是为了在每30秒的这个时间节点，做自己想做的事，这里沿用之前的 Runnable ，因为每个数据流的处理都是独立的，也不存在节省资源、复用等。</p>
<p>这样一个融合在 Flink 中，依靠多 source （其中有一个 source 是我们模拟的）实现的定时任务就完成了，在集群 flink 中表现比较理想。</p>
<p>当然，如果 source 更复杂，或者定时任务更独立一些，我想我会把它提出去当另一个 job 去做了。</p>
<p>（慢慢感受 flink 的精妙设计</p>
</div></div><div class="footer"><div class="footer-copyright">Theme By <a href="https://github.com/shinux/hexo-theme-adoubi">Adoubi</a> , Powered By Hexo.</div></div></body></html>